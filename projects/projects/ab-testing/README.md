# Experiment-Driven Feature Impact Analysis (A/B Testing)

## Problem Statement
Product teams frequently test new features before full deployment. This project simulates
an A/B testing framework to evaluate feature effectiveness.

## Objective
- Measure the impact of a new feature
- Apply statistical hypothesis testing
- Support data-backed decision making

## Methodology
- Define null and alternative hypotheses
- Compare control and treatment groups
- Perform statistical tests to assess significance
- Interpret results from a business perspective

## Tools
Python, Statistics, Data Visualization

## Key Learning
This project demonstrates experimentation, validation, and interpretation of results,
which are essential for data-driven product development.
